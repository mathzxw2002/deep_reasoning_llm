# deep_reasoning_llm

commands of docker 
https://www.runoob.com/docker/docker-command-manual.html


# TODO
- [ ] Llama Nemotron VLM Dataset V1:( https://huggingface.co/blog/nvidia/nvidia-vlm-dataset-v1), Model: https://huggingface.co/nvidia/Llama-3.1-Nemotron-Nano-VL-8B-V1
- [ ] Multimodel Reasoning, e.g. GLM-4.5V
- [ ] Cosmos-Reason1 (https://github.com/nvidia-cosmos/cosmos-reason1) Cosmos-Reason1 models understand the physical common sense and generate appropriate embodied decisions in natural language through long chain-of-thought reasoning processes.
- [ ] Code w/ Claude Developer Conference (Claude Code https://www.youtube.com/playlist?list=PLf2m23nhTg1P5BsOHUOXyQz5RhfUSSVUi )

# LLM Training Framework

## LLaMA-Factory
https://github.com/hiyouga/LLaMA-Factory
<img width="1400" height="400" alt="image" src="https://github.com/user-attachments/assets/d07b207b-7882-4de7-a376-f5d155d244a8" />

## ms-swift
https://github.com/modelscope/ms-swift
<img width="2048" height="544" alt="image" src="https://github.com/user-attachments/assets/2533eade-9d7f-4253-b8a9-62baec8060b4" />

## unsloth

<img width="512" height="512" alt="image" src="https://github.com/user-attachments/assets/dbdd0369-fee3-4a23-ac7b-a56e836c6be2" />

https://unsloth.ai/

## trl
https://huggingface.co/docs/trl/index

<img width="363" height="90" alt="image" src="https://github.com/user-attachments/assets/3192f1c3-fa76-4c98-917a-ba69563799e8" />

Fine-Tuning a Vision Language Model (Qwen2-VL-7B) with the Hugging Face Ecosystem (TRL)

https://huggingface.co/learn/cookbook/en/fine_tuning_vlm_trl


https://huggingface.co/blog/vllm-colocate

## transformers
<img width="2240" height="780" alt="image" src="https://github.com/user-attachments/assets/75f1917b-3f70-4bb5-9f31-89d5648c5cbc" />

https://github.com/huggingface/transformers

https://huggingface.co/blog/smollm3

https://huggingface.co/blog/smolvlm2

https://github.com/huggingface/smollm

https://github.com/merveenoyan/smol-vision

# RAG


# LLM Inference Framework

## Vllm

## ollama

## https://github.com/NVIDIA/TensorRT-LLM

## optimum onnx
https://github.com/huggingface/optimum


# MCP

## FastAPI-MCP
https://github.com/tadata-org/fastapi_mcp

About
Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!

fastapi-mcp.tadata.com/

## Windows-MCP

## Pixelle-MCP

An Open-Source Multimodal AIGC Solution based on ComfyUI + MCP + LLM https://pixelle.ai
https://github.com/AIDC-AI/Pixelle-MCP

## Model compression toolkit

https://github.com/Tencent/AngelSlim



## LLM Cache

https://lmcache.ai/

Accelerating the Future of AI, One Cache at a Time

Supercharge Your LLM with the Fastest KV Cache Layer 

https://github.com/LMCache/LMCache

<img width="3630" height="1480" alt="image" src="https://github.com/user-attachments/assets/1a984910-5c1d-49dd-bccf-69f35f3cab77" />

https://github.com/LMCache/demo/tree/master/demo4-compare-with-vllm

<img width="1696" height="601" alt="image" src="https://github.com/user-attachments/assets/14ee6a14-d0c0-417a-b05b-5d743b1579c4" />



# World Model

## Genie 3

## Skywork Matrix-Game 2.0

# Model on Device

## Gemma-3-270M

## Liquid AI

https://www.liquid.ai/

https://huggingface.co/LiquidAI/LFM2-VL-1.6B

Introducing LFM2: The Fastest On-Device Foundation Models on the Market

<img width="2391" height="1274" alt="image" src="https://github.com/user-attachments/assets/7ceebe08-5669-4aba-a7ad-d5e6497731dd" />




