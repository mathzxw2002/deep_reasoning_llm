


## RWKV: Reinventing RNNs for the Transformer Era
https://arxiv.org/pdf/2305.13048

https://github.com/RWKV/rwkv.cpp


<img width="846" height="1090" alt="image" src="https://github.com/user-attachments/assets/325f637e-91bd-4a7c-a91b-4d4e10edc037" />


## Quantization formats

https://bentoml.com/llm/getting-started/llm-quantization

<img width="1224" height="755" alt="image" src="https://github.com/user-attachments/assets/45ab49d8-cce2-4c39-8c57-41b8913fda92" />


## AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration

<img width="2016" height="462" alt="image" src="https://github.com/user-attachments/assets/9601966e-0180-4388-bf2b-68d93b75d06e" />


https://github.com/mit-han-lab/llm-awq


## 
